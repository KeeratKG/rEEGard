{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries \n",
    "import pandas as pd\n",
    "import scipy \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow \n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "#from tensorflow import set_random_seed\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "#read in the data using pandas \n",
    "data=pd.read_csv(\"/home/keerat/Desktop/Latest_features.csv\")\n",
    "\n",
    "#check the data has been read in properly \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find size, shape, dimension of the Latest_features preprocessed data \n",
    "size=data.size\n",
    "shape=data.shape\n",
    "df_ndim=data.ndim\n",
    "\n",
    "#print the size, shape, dimension found \n",
    "print(\"Size:{}\\nShape:{}\\nNumber of Dimensions:{}\".format(size, shape, df_ndim))\n",
    "\n",
    "#segregate features and labels \n",
    "\n",
    "X=data.drop('Label', axis=1)\n",
    "X=X.drop(X.columns[0], axis=1)\n",
    "y=data[\"Label\"]\n",
    "#check that the target variable has been removed \n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "#find size, shape, dimension of the new Bern Barcelona preprocessed data \n",
    "size_X=X.size\n",
    "[m, n]=shape_X=X.shape\n",
    "X_ndim=X.ndim\n",
    "\n",
    "size_y=y.size\n",
    "shape_y=y.shape\n",
    "y_ndim=y.ndim\n",
    "\n",
    "print(\"For X\\nSize:{}\\nShape:{}\\nNumber of Dimensions:{}\".format(size_X, shape_X, X_ndim))\n",
    "print(\"For y\\nSize:{}\\nShape:{}\\nNumber of Dimensions:{}\".format(size_y, shape_y, y_ndim))\n",
    "\n",
    "# print m,n also \n",
    "print(\"Number of features=\", n, \"\\nNumber of training examples=\", m)\n",
    "\n",
    "#Label Encoding \n",
    "print(data.Label.value_counts())\n",
    "le = LabelEncoder().fit_transform(y)\n",
    "\n",
    "print(le)\n",
    "#output suggests N=1 and F=0\n",
    "\n",
    "#train-test-cv split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, le, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test = sc.fit_transform(X_test.astype(np.float))\n",
    "X_val=sc.fit_transform(X_val.astype(np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "my_init = tensorflow.keras.initializers.glorot_normal(seed=1)\n",
    "#add layers to the model \n",
    "model=Sequential()\n",
    "#input layer\n",
    "model.add(Dropout(rate=0.2, input_shape=(88,)))\n",
    "model.add(Dense(input_shape=(88,), units=20, kernel_initializer=my_init, activation='relu', kernel_constraint=max_norm(4.)))\n",
    "#first hidden layer \n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Dense(units=20, kernel_initializer=my_init, activation='relu', kernel_constraint=max_norm(4.)))\n",
    "#dropout layer\n",
    "model.add(Dropout(rate=0.4))\n",
    "#output layer \n",
    "model.add(Dense(units=1, kernel_initializer=my_init, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history= model.fit(X_train, y_train, validation_split=0.25, batch_size=3, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history with accuracy as parameter \n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='CV accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#evaluation on test set\n",
    "test_loss, test_acc=model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy on test set:\", test_acc)\n",
    "train_loss, train_acc=model.evaluate(X_train, y_train)\n",
    "print(\"\\nAccuracy on training set:\", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use EarlyStopping and ModelCheckpoint to reduce overfitting \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#simple early stopping \n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1)\n",
    "# fit model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=1000, verbose=0, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# fit model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=1000, verbose=0, callbacks=[es, mc])\n",
    "# load the saved model\n",
    "saved_model = load_model('best_model.h5')\n",
    "#evaluation\n",
    "test_loss, test_acc= saved_model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy on test set:\", test_acc)\n",
    "test_loss, train_acc= saved_model.evaluate(X_train, y_train)\n",
    "print(\"\\nAccuracy on training set:\", train_acc)\n",
    "# plot training history\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='CV accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from hyperas.distributions import uniform, choice\n",
    "\n",
    "from random import randint\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.utils import np_utils\n",
    "from hyperas import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    #read in the data using pandas \n",
    "    data=pd.read_csv(\"/home/keerat/Desktop/Latest_features.csv\")\n",
    "\n",
    "    #check the data has been read in properly \n",
    "    data.head()\n",
    "    \n",
    "    #find size, shape, dimension of the Latest_features preprocessed data \n",
    "    size=data.size\n",
    "    shape=data.shape\n",
    "    df_ndim=data.ndim\n",
    "\n",
    "    #print the size, shape, dimension found \n",
    "    print(\"Size:{}\\nShape:{}\\nNumber of Dimensions:{}\".format(size, shape, df_ndim))\n",
    "    \n",
    "    #segregate features and labels \n",
    "\n",
    "    X=data.drop('Label', axis=1)\n",
    "    X=X.drop(X.columns[0], axis=1)\n",
    "    y=data[\"Label\"]\n",
    "    \n",
    "    #Label Encoding \n",
    "    print(data.Label.value_counts())\n",
    "    le = LabelEncoder().fit_transform(y)\n",
    "\n",
    "    print(le)\n",
    "    #output suggests N==1 and F=0\n",
    "    \n",
    "    #train-test-cv split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test= train_test_split(X, le, test_size=0.2, random_state=1)\n",
    "\n",
    "    X_train, X_val, y_train, y_val= train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "    \n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "    X_test = sc.fit_transform(X_test.astype(np.float))\n",
    "    X_val=sc.fit_transform(X_val.astype(np.float))\n",
    "        \n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unregularised #without changing the lr\n",
    "def model(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    from keras import initializers\n",
    "    from keras import backend as K\n",
    "    list_units=list(range(0,21))\n",
    "    \n",
    "    my_init=keras.initializers.glorot_normal(seed=1)\n",
    "    #add layers to the model \n",
    "    model=Sequential()\n",
    "    #input layer\n",
    "    model.add(Dropout({{uniform(0,1)}}, input_shape=(88,)))\n",
    "    model.add(Dense(units={{choice(list(range(0,21)))}}, kernel_initializer=my_init, activation='relu', \n",
    "                    kernel_constraint=max_norm(4.)))\n",
    "    #first hidden layer \n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    model.add(Dense(units={{choice(list(range(0,21)))}}, kernel_initializer=my_init, activation='relu', \n",
    "                           kernel_constraint=max_norm(4.)))\n",
    "    model.add(Dropout({{uniform(0,1)}}))\n",
    "    #output layer \n",
    "    model.add(Dense(units=1, kernel_initializer=my_init, activation='sigmoid'))\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer={{choice(['rmsprop', 'adam', 'sgd'])}}, \n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    result= model.fit(X_train, y_train, validation_split=0.25, \n",
    "                       batch_size={{choice([8, 16, 32, 64, 128, 256])}}, epochs=1000, verbose=0)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "    \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperas import optim\n",
    "from hyperopt import hp\n",
    "# SMBO - TPE in action\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=2,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Run 2_1d-Automated.Hyp.Opt.',\n",
    "                                      keep_temp=False)\n",
    "\n",
    "# Show the results\n",
    "X_train, y_train, X_test, y_test = data()\n",
    "print(\"Evaluation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt\n",
    "# os.listdir('.')\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Copy/download the file\n",
    "fid = drive.ListFile({'q':\"title='notebook.ipynb'\"}).GetList()[0]['id']\n",
    "f = drive.CreateFile({'id': fid})\n",
    "f.GetContentFile('notebook.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#using Gaussian kernel\n",
    "svclassifier = SVC(kernel='rbf')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "#prediction and evaluation\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using sigmoid kernel \n",
    "svclassifier = SVC(kernel='sigmoid')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "\n",
    "#prediction and evaluation\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(1, 20):\n",
    "    #using poly kernel \n",
    "    svclassifier = SVC(kernel='poly', degree=degree)\n",
    "    svclassifier.fit(X_train, y_train)\n",
    "\n",
    "    #prediction and evaluation\n",
    "    y_pred = svclassifier.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#create a model with 100 trees\n",
    "values=[]\n",
    "for i in range(600, 700):\n",
    "    model = RandomForestClassifier(n_estimators=i, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "    model.fit(X_train, y_train)\n",
    "    # Actual class predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    values.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Maximum Accuracy:\"+str(max(values)))\n",
    "\n",
    "# print(model.summary())\n",
    "# #evaluation on test set\n",
    "# test_loss, test_acc=model.evaluate(X_test, y_test)\n",
    "# print(\"Accuracy on test set:\", test_acc)\n",
    "# train_loss, train_acc=model.evaluate(X_train, y_train)\n",
    "# print(\"\\nAccuracy on training set:\", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "#Performance with recommended params \n",
    "from sklearn import model_selection\n",
    "model = RandomForestClassifier(n_estimators= 600, min_samples_split= 10, min_samples_leaf= 4, max_features='sqrt',\n",
    "                            max_depth= 90, bootstrap= False)\n",
    "model.fit(X_train, y_train)\n",
    "# Actual class predictions\n",
    "y_pred = model.predict(X_test)\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed, cv=kfold)\n",
    "results = model_selection.cross_val_score(model, X_test, y_test)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the recommended params for different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "seed = 7\n",
    "num_trees = 700\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees Classifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "seed = 7\n",
    "num_trees = 600\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagged Decision Tree\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cart=DecisionTreeClassifier()\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#AdaBoost Classifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "seed = 7\n",
    "num_trees = 600\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Boosting Classification\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "seed = 7\n",
    "num_trees = 200\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard Voting Ensemble \n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression(solver='liblinear')\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC(gamma='scale')\n",
    "estimators.append(('svm', model3))\n",
    "# model4 = GaussianNB()\n",
    "# estimators.append(('gnb', model4))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "results = model_selection.cross_val_score(ensemble, X_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soft Voting Ensemble \n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression(solver='liblinear')\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC(gamma='scale', probability=True)\n",
    "estimators.append(('svm', model3))\n",
    "# model4 = GaussianNB()\n",
    "# estimators.append(('gnb', model4))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "results = model_selection.cross_val_score(ensemble, X_test, y_test, error_score='raise', cv=kfold)\n",
    "print(results.mean())\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
